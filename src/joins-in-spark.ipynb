{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Joins in Spark\n",
    "\n",
    "We will explore these topics in this notebook:\n",
    "1. Natural vs Regular Joins Expressions\n",
    "2. Filter Pushdown for Joins\n",
    "3. Joining on Skewed Data\n",
    "4. Range Joins Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Find examples where you would bucket your joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession. No need to create SparkContext\n",
    "# You automatically get it as part of the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Exploring Joins\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1: Natural vs Regular Joins\n",
    "\n",
    "Two types of joins:\n",
    "1. `Natural Join`  \n",
    "    A Natural Join is where 2 tables are joined on the basis of all common columns.      \n",
    "    ie. `left.join(right, 'key')`\n",
    "\n",
    "\n",
    "2. `Regular Join`  \n",
    "    A Inner Join is where 2 tables are joined on the basis of common columns mentioned in the ON clause.\n",
    "    ie. `left.join(right, left[lkey] == right[rkey])`\n",
    "\n",
    "**Question:**\n",
    "    Is `rename`ing a `column` then doing a `natural join` better than doing an `inner join`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  data_id val_1\n",
       "0   1        1     a\n",
       "1   2        1     b\n",
       "2   2        2     c"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 1, 'a'), \n",
    "        (2, 1, 'b'), \n",
    "        (2, 2, 'c'), \n",
    "    ], ['id', 'data_id', 'val_1']\n",
    ")\n",
    "\n",
    "df_1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id  val_2\n",
       "0        1        1     10\n",
       "1        2        2     20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 1, 10), \n",
    "        (2, 2, 20), \n",
    "    ], ['shop_id', 'data_id', 'val_2']\n",
    ")\n",
    "\n",
    "df_2.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Rename Key, then Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id val_1  data_id  val_2\n",
       "0        1        1     a        1     10\n",
       "1        2        1     b        2     20\n",
       "2        2        2     c        2     20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = df_1.withColumnRenamed('id', 'shop_id')\n",
    "\n",
    "df = df_3.join(df_2, 'shop_id')\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [shop_id#12L, data_id#1L, val_1#2, data_id#7L, val_2#8L]\n",
      "+- *(5) SortMergeJoin [shop_id#12L], [shop_id#6L], Inner\n",
      "   :- *(2) Sort [shop_id#12L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(shop_id#12L, 200)\n",
      "   :     +- *(1) Project [id#0L AS shop_id#12L, data_id#1L, val_1#2]\n",
      "   :        +- *(1) Filter isnotnull(id#0L)\n",
      "   :           +- Scan ExistingRDD[id#0L,data_id#1L,val_1#2]\n",
      "   +- *(4) Sort [shop_id#6L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(shop_id#6L, 200)\n",
      "         +- *(3) Filter isnotnull(shop_id#6L)\n",
      "            +- Scan ExistingRDD[shop_id#6L,data_id#7L,val_2#8L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Don't Rename, Regular Join, Drop Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id val_1  shop_id  data_id  val_2\n",
       "0        1     a        1        1     10\n",
       "1        1     b        2        2     20\n",
       "2        2     c        2        2     20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_condition = df_1['id'] == df_2['shop_id']\n",
    "\n",
    "df = df_1.join(df_2, join_condition).drop(df_1['id'])\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [data_id#1L, val_1#2, shop_id#6L, data_id#7L, val_2#8L]\n",
      "+- *(5) SortMergeJoin [id#0L], [shop_id#6L], Inner\n",
      "   :- *(2) Sort [id#0L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(id#0L, 200)\n",
      "   :     +- *(1) Filter isnotnull(id#0L)\n",
      "   :        +- Scan ExistingRDD[id#0L,data_id#1L,val_1#2]\n",
      "   +- *(4) Sort [shop_id#6L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(shop_id#6L, 200)\n",
      "         +- *(3) Filter isnotnull(shop_id#6L)\n",
      "            +- Scan ExistingRDD[shop_id#6L,data_id#7L,val_2#8L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "Option #1\n",
    "* Looks nicer and more elegant.\n",
    "* Does it perform better though?\n",
    "\n",
    "Option #2\n",
    "* There is one less project as expected without the `withColumnRenamed`.\n",
    "\n",
    "Is this better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 2: Filter Pushdown\n",
    "\n",
    "`Filter pushdown` improves performance by reducing the amount of data shuffled during any dataframes transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id val_1\n",
       "0        1        1     a\n",
       "1        2        1     b\n",
       "2        2        2     c"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 1, 'a'), \n",
    "        (2, 1, 'b'), \n",
    "        (2, 2, 'c'), \n",
    "    ], ['shop_id', 'data_id', 'val_1']\n",
    ")\n",
    "\n",
    "df_1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id  val_2\n",
       "0        1        1     10\n",
       "1        2        2     20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 1, 10), \n",
    "        (2, 2, 20), \n",
    "    ], ['shop_id', 'data_id', 'val_2']\n",
    ")\n",
    "\n",
    "df_2.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #1: Join data, then Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  shop_id val_1  val_2\n",
       "0        1        1     a     10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = df_1.join(df_2.drop('shop_id'), 'data_id').filter(F.col('shop_id') == 1)\n",
    "\n",
    "df_3.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [data_id#45L, shop_id#44L, val_1#46, val_2#52L]\n",
      "+- *(5) SortMergeJoin [data_id#45L], [data_id#51L], Inner\n",
      "   :- *(2) Sort [data_id#45L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(data_id#45L, 200)\n",
      "   :     +- *(1) Filter ((isnotnull(shop_id#44L) && (shop_id#44L = 1)) && isnotnull(data_id#45L))\n",
      "   :        +- Scan ExistingRDD[shop_id#44L,data_id#45L,val_1#46]\n",
      "   +- *(4) Sort [data_id#51L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(data_id#51L, 200)\n",
      "         +- *(3) Project [data_id#51L, val_2#52L]\n",
      "            +- *(3) Filter isnotnull(data_id#51L)\n",
      "               +- Scan ExistingRDD[shop_id#50L,data_id#51L,val_2#52L]\n"
     ]
    }
   ],
   "source": [
    "df_3.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened:**\n",
    "\n",
    "* We can see that the filter is after the join and not pushed down. \n",
    "* This means all of the data is brough to the join.\n",
    "* Then the filter is done.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "We bring more data to the join and shuffle, **this is bad**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #2: Join on Filter Key, Filter After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id val_1  val_2\n",
       "0        1        1     a     10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4 = df_1.join(df_2, ['shop_id', 'data_id']).filter(F.col('shop_id') == 1)\n",
    "\n",
    "df_4.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [shop_id#44L, data_id#45L, val_1#46, val_2#52L]\n",
      "+- *(5) SortMergeJoin [shop_id#44L, data_id#45L], [shop_id#50L, data_id#51L], Inner\n",
      "   :- *(2) Sort [shop_id#44L ASC NULLS FIRST, data_id#45L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(shop_id#44L, data_id#45L, 200)\n",
      "   :     +- *(1) Filter ((isnotnull(shop_id#44L) && (shop_id#44L = 1)) && isnotnull(data_id#45L))\n",
      "   :        +- Scan ExistingRDD[shop_id#44L,data_id#45L,val_1#46]\n",
      "   +- *(4) Sort [shop_id#50L ASC NULLS FIRST, data_id#51L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(shop_id#50L, data_id#51L, 200)\n",
      "         +- *(3) Filter (((shop_id#50L = 1) && isnotnull(data_id#51L)) && isnotnull(shop_id#50L))\n",
      "            +- Scan ExistingRDD[shop_id#50L,data_id#51L,val_2#52L]\n"
     ]
    }
   ],
   "source": [
    "df_4.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened:**\n",
    "* The filter got pushed down.\n",
    "* Less data is brought to the join and shuffle.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "We bring less data to the join and shuffle, **this is good**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #3: Filter Left, then Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  shop_id val_1  val_2\n",
       "0        1        1     a     10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5 = df_1.filter(F.col('shop_id') == 1).join(df_2.drop('shop_id'), 'data_id')\n",
    "\n",
    "df_5.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [data_id#45L, shop_id#44L, val_1#46, val_2#52L]\n",
      "+- *(5) SortMergeJoin [data_id#45L], [data_id#51L], Inner\n",
      "   :- *(2) Sort [data_id#45L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(data_id#45L, 200)\n",
      "   :     +- *(1) Filter ((isnotnull(shop_id#44L) && (shop_id#44L = 1)) && isnotnull(data_id#45L))\n",
      "   :        +- Scan ExistingRDD[shop_id#44L,data_id#45L,val_1#46]\n",
      "   +- *(4) Sort [data_id#51L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(data_id#51L, 200)\n",
      "         +- *(3) Project [data_id#51L, val_2#52L]\n",
      "            +- *(3) Filter isnotnull(data_id#51L)\n",
      "               +- Scan ExistingRDD[shop_id#50L,data_id#51L,val_2#52L]\n"
     ]
    }
   ],
   "source": [
    "df_5.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened:**\n",
    "* This is exactly the same as case 1.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "We bring less data to the join and shuffle, **this is bad**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #4: Filter Both, then Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  shop_id val_1  val_2\n",
       "0        1        1     a     10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6 = df_1.filter(F.col('shop_id') == 1).join(\n",
    "    df_2.filter(F.col('shop_id') == 1).drop('shop_id'), \n",
    "    'data_id'\n",
    ")\n",
    "\n",
    "df_6.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [data_id#45L, shop_id#44L, val_1#46, val_2#52L]\n",
      "+- *(5) SortMergeJoin [data_id#45L], [data_id#51L], Inner\n",
      "   :- *(2) Sort [data_id#45L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(data_id#45L, 200)\n",
      "   :     +- *(1) Filter ((isnotnull(shop_id#44L) && (shop_id#44L = 1)) && isnotnull(data_id#45L))\n",
      "   :        +- Scan ExistingRDD[shop_id#44L,data_id#45L,val_1#46]\n",
      "   +- *(4) Sort [data_id#51L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(data_id#51L, 200)\n",
      "         +- *(3) Project [data_id#51L, val_2#52L]\n",
      "            +- *(3) Filter ((isnotnull(shop_id#50L) && (shop_id#50L = 1)) && isnotnull(data_id#51L))\n",
      "               +- Scan ExistingRDD[shop_id#50L,data_id#51L,val_2#52L]\n"
     ]
    }
   ],
   "source": [
    "df_6.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "* We should always try to push the filter down as much as possible. \n",
    "* This means that there will be less data being shuffled and joined during the join. \n",
    "* This can be achieved with join in case #2 or #4.\n",
    "\n",
    "**Option #2** (Good)\n",
    "* When we `join`ed on `filter`ed on the key `shop_id` this caused a `filter-pushdown` which is good.\n",
    "* But this made us `sort` on 2 keys.\n",
    "\n",
    "**Option #4** (Better)\n",
    "* When we pre `filter` the `join`ing datasets, this caused a `filter-pushdown` which is good.\n",
    "* We only `join` on one key as well, which is good as we only sort on 1 key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 3: Joins on Skewed Data\n",
    "\n",
    "A `skewed dataset` is defined by a dataset that has a class imbalance, this leads to poor or uncompletable spark jobs often getting `OOM` (out of memory) errors.\n",
    "\n",
    "When performing a `join` onto a `skewed dataset` it means that there exists a class imbalance on the `key`s on which the join is performed on. This results in a majority of the data falls onto one partition, which will take longer to complete than the other partitions.\n",
    "\n",
    "Some examples of this are:\n",
    "1. The keys consist mainly of `null` values which fall onto a single partition.\n",
    "2. There is a subset of keys that makeup the majority percentage of the keys which fall onto a single partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Situation 1: Null Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inital Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>card_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  card_id\n",
       "0   1      NaN\n",
       "1   2      NaN\n",
       "2   3      1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers = spark.createDataFrame([\n",
    "    (1, None), \n",
    "    (2, None), \n",
    "    (3, 1),\n",
    "], [\"id\", \"card_id\"])\n",
    "\n",
    "customers.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rick</td>\n",
       "      <td>roll</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bob</td>\n",
       "      <td>brown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id first_name last_name  age\n",
       "0        1       john       doe   21\n",
       "1        2       rick      roll   10\n",
       "2        3        bob     brown    2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards = spark.createDataFrame([\n",
    "    (1, \"john\", \"doe\", 21), \n",
    "    (2, \"rick\", \"roll\", 10), \n",
    "    (3, \"bob\", \"brown\", 2)\n",
    "], [\"card_id\", \"first_name\", \"last_name\", \"age\"])\n",
    "\n",
    "cards.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #1: Join Regularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id  id first_name last_name   age\n",
       "0      NaN   1       None      None   NaN\n",
       "1      NaN   2       None      None   NaN\n",
       "2      1.0   3       john       doe  21.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = customers.join(cards, \"card_id\", \"left\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [card_id#84L, id#83L, first_name#88, last_name#89, age#90L]\n",
      "+- SortMergeJoin [card_id#84L], [card_id#87L], LeftOuter\n",
      "   :- *(1) Sort [card_id#84L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(card_id#84L, 200)\n",
      "   :     +- Scan ExistingRDD[id#83L,card_id#84L]\n",
      "   +- *(2) Sort [card_id#87L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(card_id#87L, 200)\n",
      "         +- Scan ExistingRDD[card_id#87L,first_name#88,last_name#89,age#90L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* Rows that didn't join up were brought to the join.\n",
    "* They get `Null` values for the right side columns.\n",
    "\n",
    "**Results**:\n",
    "* We brought more data to the join than we had to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #2: Filter Null Keys First, then Join, then Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  card_id first_name last_name   age\n",
       "0   1      NaN       None      None   NaN\n",
       "1   2      NaN       None      None   NaN\n",
       "2   3      1.0       john       doe  21.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def null_skew_helper(left, right, key):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "        1. Filter out the null rows.\n",
    "        2. Create the columns you would get from the join.\n",
    "        3. Join the tables.\n",
    "        4. Union the null rows to joined table.\n",
    "    \"\"\"\n",
    "    df1 = left.where(F.col(key).isNull())\n",
    "    for f in right.schema.fields:\n",
    "            df1 = df1.withColumn(f.name, F.lit(None).cast(f.dataType))\n",
    "    \n",
    "    df2 = left.where(F.col(key).isNotNull())\n",
    "    df2 = df2.join(right, key, \"left\")\n",
    "    \n",
    "    return df1.union(df2.select(df1.columns))\n",
    "    \n",
    "    \n",
    "df = null_skew_helper(customers, cards, \"card_id\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Union\n",
      ":- *(1) Project [id#83L, null AS card_id#101L, null AS first_name#104, null AS last_name#108, null AS age#113L]\n",
      ":  +- *(1) Filter isnull(card_id#84L)\n",
      ":     +- Scan ExistingRDD[id#83L,card_id#84L]\n",
      "+- *(5) Project [id#83L, card_id#84L, first_name#88, last_name#89, age#90L]\n",
      "   +- SortMergeJoin [card_id#84L], [card_id#87L], LeftOuter\n",
      "      :- *(3) Sort [card_id#84L ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(card_id#84L, 200)\n",
      "      :     +- *(2) Filter isnotnull(card_id#84L)\n",
      "      :        +- Scan ExistingRDD[id#83L,card_id#84L]\n",
      "      +- *(4) Sort [card_id#87L ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(card_id#87L, 200)\n",
      "            +- Scan ExistingRDD[card_id#87L,first_name#88,last_name#89,age#90L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* We filtered all the rows out before the join.\n",
    "* We did the join with less data.\n",
    "* We read the table again and got the null rows.\n",
    "* Unioned with the joined results.\n",
    "\n",
    "**Results**:\n",
    "* We brought less data to the join.\n",
    "* But we read the data twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #3: Cache Table, Filter Null Keys First, then Join, then Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  card_id first_name last_name   age\n",
       "0   1      NaN       None      None   NaN\n",
       "1   2      NaN       None      None   NaN\n",
       "2   3      1.0       john       doe  21.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def null_skew_helper(left, right, key):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "        1. Filter out the null rows.\n",
    "        2. Create the columns you would get from the join.\n",
    "        3. Join the tables.\n",
    "        4. Union the null rows to joined table.\n",
    "    \"\"\"\n",
    "    left = left.cache()\n",
    "    \n",
    "    df1 = left.where(F.col(key).isNull())\n",
    "    for f in right.schema.fields:\n",
    "            df1 = df1.withColumn(f.name, F.lit(None).cast(f.dataType))\n",
    "    \n",
    "    df2 = left.where(F.col(key).isNotNull())\n",
    "    df2 = df2.join(right, key, \"left\")\n",
    "    \n",
    "    return df1.union(df2.select(df1.columns))\n",
    "    \n",
    "    \n",
    "df = null_skew_helper(customers, cards, \"card_id\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Union\n",
      ":- *(1) Project [id#83L, null AS card_id#146L, null AS first_name#149, null AS last_name#153, null AS age#158L]\n",
      ":  +- *(1) Filter isnull(card_id#84L)\n",
      ":     +- *(1) InMemoryTableScan [card_id#84L, id#83L], [isnull(card_id#84L)]\n",
      ":           +- InMemoryRelation [id#83L, card_id#84L], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      ":                 +- Scan ExistingRDD[id#83L,card_id#84L]\n",
      "+- *(5) Project [id#83L, card_id#84L, first_name#88, last_name#89, age#90L]\n",
      "   +- SortMergeJoin [card_id#84L], [card_id#87L], LeftOuter\n",
      "      :- *(3) Sort [card_id#84L ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(card_id#84L, 200)\n",
      "      :     +- *(2) Filter isnotnull(card_id#84L)\n",
      "      :        +- *(2) InMemoryTableScan [id#83L, card_id#84L], [isnotnull(card_id#84L)]\n",
      "      :              +- InMemoryRelation [id#83L, card_id#84L], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :                    +- Scan ExistingRDD[id#83L,card_id#84L]\n",
      "      +- *(4) Sort [card_id#87L ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(card_id#87L, 200)\n",
      "            +- Scan ExistingRDD[card_id#87L,first_name#88,last_name#89,age#90L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* Similar to option #2, but we did a `InMemoryTableScan` instead of a read of the data.\n",
    "\n",
    "**Results**:\n",
    "* We brought less data to the join.\n",
    "* We did 1 less read, but we used more memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "As always there is pros and cons.\n",
    "\n",
    "Pros:\n",
    "* Ideally you want to bring less data to a join. \n",
    "* This is unneeded data and in most cases causes a spark job to fail. \n",
    "* This is due to the fact that all the null key rows will go onto one partition.\n",
    "\n",
    "Cons:\n",
    "* There will either be one extra read of data or more memory used.\n",
    "\n",
    "All to say:\n",
    "1. It's definitely better to bring less data to a join, so do a filter of the null keys before the join.\n",
    "2. This will result in an extra read of data or memory usage.\n",
    "3. Decide if you can afford the extra read vs memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 4: Range Join Conditions\n",
    "\n",
    "> A naive approach (just specifying this as the range condition) would result in a full cartesian product and a filter that enforces the condition (tested using Spark 2.0). This has a horrible effect on performance, especially if DataFrames are more than a few hundred thousands records.\n",
    "\n",
    "source: http://zachmoshe.com/2016/09/26/efficient-range-joins-with-spark.html\n",
    "\n",
    "> The source of the problem is pretty simple. When you execute join and join condition is not equality based the only thing that Spark can do right now is expand it to Cartesian product followed by filter what is pretty much what happens inside `BroadcastNestedLoopJoin`\n",
    "\n",
    "source: https://stackoverflow.com/questions/37953830/spark-sql-performance-join-on-value-between-min-and-max?answertab=active#tab-top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipstart</th>\n",
       "      <th>ipend</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ipstart  ipend  loc\n",
       "0        1     10  foo\n",
       "1       11     36  bar\n",
       "2       37     59  baz"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_loc_table = sqlc.createDataFrame([\n",
    "    (1, 10, \"foo\"), \n",
    "    (11, 36, \"bar\"), \n",
    "    (37, 59, \"baz\"),\n",
    "], [\"ipstart\", \"ipend\", \"loc\"])\n",
    "\n",
    "geo_loc_table.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>inet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  inet\n",
       "0   1    11\n",
       "1   2    38\n",
       "2   3    50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_table = sqlc.createDataFrame([\n",
    "    (1, 11), \n",
    "    (2, 38), \n",
    "    (3, 50),\n",
    "],[\"id\", \"inet\"])\n",
    "\n",
    "records_table.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>inet</th>\n",
       "      <th>ipstart</th>\n",
       "      <th>ipend</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  inet  ipstart  ipend  loc\n",
       "0   1    11       11     36  bar\n",
       "1   2    38       37     59  baz\n",
       "2   3    50       37     59  baz"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_condition = [\n",
    "    records_table['inet'] >= geo_loc_table['ipstart'],\n",
    "    records_table['inet'] <= geo_loc_table['ipend'],\n",
    "]\n",
    "\n",
    "df = records_table.join(geo_loc_table, join_condition, \"left\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "BroadcastNestedLoopJoin BuildRight, LeftOuter, ((inet#90L >= ipstart#83L) && (inet#90L <= ipend#84L))\n",
      ":- Scan ExistingRDD[id#89L,inet#90L]\n",
      "+- BroadcastExchange IdentityBroadcastMode\n",
      "   +- Scan ExistingRDD[ipstart#83L,ipend#84L,loc#85]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipstart</th>\n",
       "      <th>id</th>\n",
       "      <th>inet</th>\n",
       "      <th>ipend</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ipstart  id  inet  ipend  loc\n",
       "0       37   2    38     59  baz\n",
       "1       37   3    50     59  baz\n",
       "2       11   1    11     36  bar"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bisect import bisect_right\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "geo_start_bd = sc.broadcast(map(lambda x: x.ipstart, geo_loc_table\n",
    "    .select(\"ipstart\")\n",
    "    .orderBy(\"ipstart\")\n",
    "    .collect()\n",
    "))\n",
    "\n",
    "def find_le(x):\n",
    "    'Find rightmost value less than or equal to x'\n",
    "    i = bisect_right(geo_start_bd.value, x)\n",
    "    if i:\n",
    "        return geo_start_bd.value[i-1]\n",
    "    return None\n",
    "\n",
    "records_table_with_ipstart = records_table.withColumn(\n",
    "    \"ipstart\", udf(find_le, LongType())(\"inet\")\n",
    ")\n",
    "\n",
    "df = records_table_with_ipstart.join(geo_loc_table, [\"ipstart\"], \"left\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) Project [ipstart#110L, id#89L, inet#90L, ipend#84L, loc#85]\n",
      "+- SortMergeJoin [ipstart#110L], [ipstart#83L], LeftOuter\n",
      "   :- *(2) Sort [ipstart#110L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(ipstart#110L, 200)\n",
      "   :     +- *(1) Project [id#89L, inet#90L, pythonUDF0#119L AS ipstart#110L]\n",
      "   :        +- BatchEvalPython [find_le(inet#90L)], [id#89L, inet#90L, pythonUDF0#119L]\n",
      "   :           +- Scan ExistingRDD[id#89L,inet#90L]\n",
      "   +- *(3) Sort [ipstart#83L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(ipstart#83L, 200)\n",
      "         +- Scan ExistingRDD[ipstart#83L,ipend#84L,loc#85]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
